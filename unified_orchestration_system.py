#!/usr/bin/env python3
"""
Sistema de Orquestaci√≥n RAG Cl√≠nico - Pipeline Completo
Meta-flujo: NLP ‚Üí Terms/PICO ‚Üí Recuperaci√≥n dual ‚Üí Filtrado ‚Üí Re-ranking ‚Üí Chunking ‚Üí LLM ‚Üí Verificaci√≥n ‚Üí APA
"""

import re
import json
import time
import logging
import hashlib
from typing import Dict, List, Tuple, Optional, Set, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import requests
from urllib.parse import quote

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Importar integraci√≥n MeSH y MedlinePlus
from mesh_integration import mesh_integration
from medlineplus_integration import (
    medlineplus_integration,
    get_patient_education_for_code,
)


class TipoEstudio(Enum):
    """Tipos de estudios cl√≠nicos"""

    RCT = "randomized_controlled_trial"
    META_ANALYSIS = "meta_analysis"
    SYSTEMATIC_REVIEW = "systematic_review"
    GUIDELINE = "guideline"
    OBSERVATIONAL = "observational"
    CASE_STUDY = "case_study"
    EXPERT_OPINION = "expert_opinion"


class NivelEvidencia(Enum):
    """Niveles de evidencia cl√≠nica"""

    A = "A"  # Meta-an√°lisis, RCTs
    B = "B"  # Estudios observacionales
    C = "C"  # Casos cl√≠nicos, opini√≥n experta
    D = "D"  # Evidencia insuficiente


@dataclass
class TerminoBusqueda:
    """T√©rmino de b√∫squeda con metadatos"""

    termino: str
    tipo: str  # "PICO", "MeSH", "keyword"
    peso: float
    fuente: str  # "NLP", "manual", "MeSH"
    confianza: float


@dataclass
class ResultadoBusqueda:
    """Resultado de b√∫squeda con metadatos"""

    titulo: str
    abstract: str
    autores: List[str]
    a√±o: int
    doi: str
    pmid: str
    fuente: str  # "PubMed", "EuropePMC"
    tipo_estudio: TipoEstudio
    nivel_evidencia: NivelEvidencia
    score_bm25: float
    score_embeddings: float
    score_final: float
    peer_reviewed: bool
    has_full_text: bool
    keywords: List[str]
    mesh_terms: List[str]


@dataclass
class ChunkConAnchors:
    """Chunk de texto con anchors para trazabilidad"""

    texto: str
    inicio_char: int
    fin_char: int
    seccion: str  # "abstract", "methods", "results", "discussion"
    parrafo: int
    oraciones: List[str]
    anchors: List[str]  # IDs √∫nicos para cada oraci√≥n
    entidades_clave: List[str]
    relevancia_clinica: float


@dataclass
class ResumenConEvidencia:
    """Resumen con evidencia requerida"""

    resumen: str
    oraciones_con_evidencia: List[
        Dict[str, Any]
    ]  # {oracion: str, citas: List[str], confianza: float}
    oraciones_sin_evidencia: List[str]
    claims_no_concluyentes: List[str]
    confianza_global: float
    # Campos para integraci√≥n MedlinePlus
    patient_education: Dict[str, str] = field(default_factory=dict)
    education_available: bool = False
    education_summary: str = ""


@dataclass
class MapeoOracionCita:
    """Mapeo oraci√≥n ‚Üî cita para auditor√≠a"""

    oracion_id: str
    oracion_texto: str
    citas: List[str]
    chunks_soporte: List[str]
    confianza: float
    timestamp: datetime


@dataclass
class ResultadoOrquestacion:
    """Resultado final del pipeline de orquestaci√≥n"""

    consulta_original: str
    terminos_busqueda: List[TerminoBusqueda]
    resultados_recuperados: List[ResultadoBusqueda]
    chunks_procesados: List[ChunkConAnchors]
    resumen_final: ResumenConEvidencia
    mapeo_oracion_cita: List[MapeoOracionCita]
    tiempo_total: float
    estadisticas: Dict[str, Any]


class GeneradorTerminosPICO:
    """Generador de t√©rminos de b√∫squeda PICO"""

    def __init__(self):
        self.patrones_pico = {
            "P": r"(pacientes?|personas?|sujetos?|individuos?|poblaci√≥n)",
            "I": r"(intervenci√≥n|tratamiento|terapia|medicamento|procedimiento)",
            "C": r"(comparador|control|placebo|est√°ndar|alternativa)",
            "O": r"(resultado|outcome|efecto|beneficio|desenlace)",
        }

    def generar_terminos(
        self, consulta: str, analisis_nlp: Dict
    ) -> List[TerminoBusqueda]:
        """Genera t√©rminos de b√∫squeda basados en PICO"""
        terminos = []

        # Extraer t√©rminos del an√°lisis NLP
        sintomas = analisis_nlp.get("sintomas", [])
        organos = analisis_nlp.get("organos", [])
        medicamentos = analisis_nlp.get("medicamentos", [])
        pico_terms = analisis_nlp.get("pico_terms", {})

        # T√©rminos P (Poblaci√≥n)
        for sintoma in sintomas:
            terminos.append(
                TerminoBusqueda(
                    termino=sintoma,
                    tipo="PICO_P",
                    peso=0.8,
                    fuente="NLP",
                    confianza=0.9,
                )
            )

        # T√©rminos I (Intervenci√≥n)
        for medicamento in medicamentos:
            terminos.append(
                TerminoBusqueda(
                    termino=medicamento,
                    tipo="PICO_I",
                    peso=0.9,
                    fuente="NLP",
                    confianza=0.8,
                )
            )

        # T√©rminos O (Outcome)
        outcomes = ["mejora", "reducci√≥n", "efectividad", "beneficio"]
        for outcome in outcomes:
            if outcome in consulta.lower():
                terminos.append(
                    TerminoBusqueda(
                        termino=outcome,
                        tipo="PICO_O",
                        peso=0.7,
                        fuente="NLP",
                        confianza=0.7,
                    )
                )

        # INTEGRACI√ìN MeSH: Usar t√©rminos MeSH reales del an√°lisis NLP
        mesh_terms = analisis_nlp.get("mesh_terms", [])
        mesh_descriptor = analisis_nlp.get("mesh_descriptor", "")
        clinical_context = analisis_nlp.get("clinical_context", {})

        # Agregar t√©rminos MeSH principales
        if mesh_descriptor:
            terminos.append(
                TerminoBusqueda(
                    termino=mesh_descriptor,
                    tipo="MeSH_primary",
                    peso=0.9,
                    fuente="MeSH",
                    confianza=0.9,
                )
            )

        # Agregar t√©rminos MeSH expandidos
        for term in mesh_terms:
            if term != mesh_descriptor:  # Evitar duplicados
                terminos.append(
                    TerminoBusqueda(
                        termino=term,
                        tipo="MeSH_expanded",
                        peso=0.7,
                        fuente="MeSH",
                        confianza=0.8,
                    )
                )

        # Agregar t√©rminos de contexto cl√≠nico
        if clinical_context.get("specialty"):
            terminos.append(
                TerminoBusqueda(
                    termino=clinical_context["specialty"],
                    tipo="clinical_context",
                    peso=0.6,
                    fuente="MeSH",
                    confianza=0.7,
                )
            )

        return terminos

    def _expandir_mesh_terms(self, terminos: List[str]) -> List[str]:
        """Expande t√©rminos usando MeSH real"""
        # Este m√©todo ahora usa la integraci√≥n MeSH real
        # La expansi√≥n se hace en el pipeline principal
        return []


class RecuperadorDual:
    """Recuperaci√≥n dual: BM25 + Embeddings"""

    def __init__(self):
        self.api_key = None  # Se configurar√° desde environment

    def recuperar_dual(
        self, terminos: List[TerminoBusqueda]
    ) -> List[ResultadoBusqueda]:
        """Recupera documentos usando BM25 + Embeddings"""
        logger.info(f"üîç Recuperaci√≥n dual con {len(terminos)} t√©rminos")

        # Construir query combinada
        query_bm25 = self._construir_query_bm25(terminos)
        query_embeddings = self._construir_query_embeddings(terminos)

        # B√∫squeda BM25 (simulada)
        resultados_bm25 = self._buscar_bm25(query_bm25)

        # B√∫squeda por embeddings (simulada)
        resultados_embeddings = self._buscar_embeddings(query_embeddings)

        # Combinar y rankear resultados
        resultados_combinados = self._combinar_resultados(
            resultados_bm25, resultados_embeddings
        )

        logger.info(f"‚úÖ {len(resultados_combinados)} resultados recuperados")
        return resultados_combinados

    def _construir_query_bm25(self, terminos: List[TerminoBusqueda]) -> str:
        """Construye query para BM25"""
        # Priorizar t√©rminos PICO
        pico_terms = [t.termino for t in terminos if t.tipo.startswith("PICO")]
        mesh_terms = [t.termino for t in terminos if t.tipo == "MeSH"]

        query_parts = []
        if pico_terms:
            query_parts.append(" AND ".join(pico_terms))
        if mesh_terms:
            query_parts.append(" OR ".join(mesh_terms))

        return (
            " AND ".join(query_parts)
            if query_parts
            else " ".join([t.termino for t in terminos])
        )

    def _construir_query_embeddings(self, terminos: List[TerminoBusqueda]) -> str:
        """Construye query para embeddings"""
        # Usar todos los t√©rminos con pesos
        weighted_terms = []
        for termino in terminos:
            weighted_terms.extend([termino.termino] * int(termino.peso * 10))

        return " ".join(weighted_terms)

    def _buscar_bm25(self, query: str) -> List[ResultadoBusqueda]:
        """B√∫squeda BM25 (simulada)"""
        # Simulaci√≥n de resultados BM25
        return [
            ResultadoBusqueda(
                titulo="Exercise therapy for knee osteoarthritis",
                abstract="Randomized controlled trial showing significant improvement...",
                autores=["Smith", "Johnson"],
                a√±o=2023,
                doi="10.1000/ejemplo1",
                pmid="12345678",
                fuente="PubMed",
                tipo_estudio=TipoEstudio.RCT,
                nivel_evidencia=NivelEvidencia.A,
                score_bm25=0.85,
                score_embeddings=0.0,
                score_final=0.85,
                peer_reviewed=True,
                has_full_text=True,
                keywords=["exercise", "knee", "osteoarthritis"],
                mesh_terms=["Exercise Therapy", "Knee Joint", "Osteoarthritis"],
            ),
            ResultadoBusqueda(
                titulo="Physical therapy outcomes in chronic pain",
                abstract="Systematic review of physical therapy interventions...",
                autores=["Brown", "Davis"],
                a√±o=2022,
                doi="10.1000/ejemplo2",
                pmid="87654321",
                fuente="EuropePMC",
                tipo_estudio=TipoEstudio.SYSTEMATIC_REVIEW,
                nivel_evidencia=NivelEvidencia.A,
                score_bm25=0.78,
                score_embeddings=0.0,
                score_final=0.78,
                peer_reviewed=True,
                has_full_text=True,
                keywords=["physical therapy", "chronic pain"],
                mesh_terms=["Physical Therapy", "Chronic Pain"],
            ),
        ]

    def _buscar_embeddings(self, query: str) -> List[ResultadoBusqueda]:
        """B√∫squeda por embeddings (simulada)"""
        # Simulaci√≥n de resultados embeddings
        return [
            ResultadoBusqueda(
                titulo="Rehabilitation strategies for joint pain",
                abstract="Comprehensive approach to joint rehabilitation...",
                autores=["Wilson", "Taylor"],
                a√±o=2023,
                doi="10.1000/ejemplo3",
                pmid="11223344",
                fuente="PubMed",
                tipo_estudio=TipoEstudio.OBSERVATIONAL,
                nivel_evidencia=NivelEvidencia.B,
                score_bm25=0.0,
                score_embeddings=0.92,
                score_final=0.92,
                peer_reviewed=True,
                has_full_text=False,
                keywords=["rehabilitation", "joint pain"],
                mesh_terms=["Rehabilitation", "Joint Pain"],
            )
        ]

    def _combinar_resultados(
        self, bm25: List[ResultadoBusqueda], embeddings: List[ResultadoBusqueda]
    ) -> List[ResultadoBusqueda]:
        """Combina y rankea resultados"""
        # Combinar resultados √∫nicos
        todos_resultados = {}

        for resultado in bm25 + embeddings:
            key = resultado.doi
            if key not in todos_resultados:
                todos_resultados[key] = resultado
            else:
                # Combinar scores
                todos_resultados[key].score_bm25 = max(
                    todos_resultados[key].score_bm25, resultado.score_bm25
                )
                todos_resultados[key].score_embeddings = max(
                    todos_resultados[key].score_embeddings, resultado.score_embeddings
                )
                todos_resultados[key].score_final = (
                    todos_resultados[key].score_bm25
                    + todos_resultados[key].score_embeddings
                ) / 2

        # Ordenar por score final
        resultados_ordenados = sorted(
            todos_resultados.values(), key=lambda x: x.score_final, reverse=True
        )

        return resultados_ordenados


class FiltradorEstudios:
    """Filtrado por dise√±o de estudio + a√±o + peer-review"""

    def __init__(self):
        self.filtros_default = {
            "a√±o_minimo": 2015,
            "peer_reviewed_only": True,
            "tipos_estudio_preferidos": [
                TipoEstudio.RCT,
                TipoEstudio.META_ANALYSIS,
                TipoEstudio.SYSTEMATIC_REVIEW,
                TipoEstudio.GUIDELINE,
            ],
            "niveles_evidencia_minimos": [NivelEvidencia.A, NivelEvidencia.B],
        }

    def filtrar_resultados(
        self, resultados: List[ResultadoBusqueda], filtros: Dict = None
    ) -> List[ResultadoBusqueda]:
        """Filtra resultados seg√∫n criterios cl√≠nicos"""
        if filtros is None:
            filtros = self.filtros_default

        logger.info(f"üîç Filtrando {len(resultados)} resultados")

        resultados_filtrados = []
        for resultado in resultados:
            if self._cumple_filtros(resultado, filtros):
                resultados_filtrados.append(resultado)

        logger.info(f"‚úÖ {len(resultados_filtrados)} resultados despu√©s del filtrado")
        return resultados_filtrados

    def _cumple_filtros(self, resultado: ResultadoBusqueda, filtros: Dict) -> bool:
        """Verifica si un resultado cumple los filtros"""
        # Filtro de a√±o
        if resultado.a√±o < filtros.get("a√±o_minimo", 2015):
            return False

        # Filtro de peer-review
        if filtros.get("peer_reviewed_only", True) and not resultado.peer_reviewed:
            return False

        # Filtro de tipo de estudio
        tipos_preferidos = filtros.get("tipos_estudio_preferidos", [])
        if tipos_preferidos and resultado.tipo_estudio not in tipos_preferidos:
            return False

        # Filtro de nivel de evidencia
        niveles_minimos = filtros.get("niveles_evidencia_minimos", [])
        if niveles_minimos and resultado.nivel_evidencia not in niveles_minimos:
            return False

        return True


class ReRankerClinico:
    """Re-ranking cl√≠nico (cross-encoder)"""

    def __init__(self):
        self.factores_ranking = {
            "tipo_estudio": {
                TipoEstudio.RCT: 1.0,
                TipoEstudio.META_ANALYSIS: 0.95,
                TipoEstudio.SYSTEMATIC_REVIEW: 0.9,
                TipoEstudio.GUIDELINE: 0.85,
                TipoEstudio.OBSERVATIONAL: 0.7,
                TipoEstudio.CASE_STUDY: 0.5,
                TipoEstudio.EXPERT_OPINION: 0.3,
            },
            "nivel_evidencia": {
                NivelEvidencia.A: 1.0,
                NivelEvidencia.B: 0.8,
                NivelEvidencia.C: 0.6,
                NivelEvidencia.D: 0.3,
            },
            "a√±o": {"factor": 0.1, "a√±o_base": 2023},  # Bonus por a√±o reciente
            "full_text": 0.1,  # Bonus por texto completo disponible
            "score_original": 0.5,  # Peso del score original
        }

    def rerank_clinico(
        self, resultados: List[ResultadoBusqueda], consulta: str
    ) -> List[ResultadoBusqueda]:
        """Aplica re-ranking cl√≠nico"""
        logger.info(f"üîÑ Re-ranking cl√≠nico de {len(resultados)} resultados")

        for resultado in resultados:
            score_clinico = self._calcular_score_clinico(resultado, consulta)
            resultado.score_final = score_clinico

        # Ordenar por score cl√≠nico
        resultados_reranked = sorted(
            resultados, key=lambda x: x.score_final, reverse=True
        )

        logger.info(f"‚úÖ Re-ranking completado")
        return resultados_reranked

    def _calcular_score_clinico(
        self, resultado: ResultadoBusqueda, consulta: str
    ) -> float:
        """Calcula score cl√≠nico basado en m√∫ltiples factores"""
        score = 0.0

        # Factor tipo de estudio
        score += self.factores_ranking["tipo_estudio"].get(resultado.tipo_estudio, 0.5)

        # Factor nivel de evidencia
        score += self.factores_ranking["nivel_evidencia"].get(
            resultado.nivel_evidencia, 0.5
        )

        # Factor a√±o
        a√±os_recientes = max(
            0, resultado.a√±o - self.factores_ranking["a√±o"]["a√±o_base"]
        )
        score += a√±os_recientes * self.factores_ranking["a√±o"]["factor"]

        # Factor texto completo
        if resultado.has_full_text:
            score += self.factores_ranking["full_text"]

        # Factor score original
        score_original = (resultado.score_bm25 + resultado.score_embeddings) / 2
        score += score_original * self.factores_ranking["score_original"]

        # Normalizar a 0-1
        return min(1.0, max(0.0, score / 3.0))


class ChunkerConAnchors:
    """Chunking con anchors para trazabilidad"""

    def __init__(self):
        self.secciones_importantes = [
            "abstract",
            "methods",
            "results",
            "discussion",
            "conclusion",
        ]

    def chunkear_con_anchors(
        self, resultados: List[ResultadoBusqueda]
    ) -> List[ChunkConAnchors]:
        """Crea chunks con anchors para trazabilidad"""
        logger.info(f"üìÑ Chunking con anchors de {len(resultados)} resultados")

        chunks = []
        for i, resultado in enumerate(resultados):
            # Chunkear abstract
            chunks_abstract = self._chunkear_texto(
                resultado.abstract, f"resultado_{i}_abstract", "abstract"
            )
            chunks.extend(chunks_abstract)

            # Si hay texto completo, chunkear secciones
            if resultado.has_full_text:
                # Simulaci√≥n de texto completo
                texto_completo = self._simular_texto_completo(resultado)
                chunks_texto = self._chunkear_texto(
                    texto_completo, f"resultado_{i}_fulltext", "full_text"
                )
                chunks.extend(chunks_texto)

        logger.info(f"‚úÖ {len(chunks)} chunks creados con anchors")
        return chunks

    def _chunkear_texto(
        self, texto: str, prefijo: str, seccion: str
    ) -> List[ChunkConAnchors]:
        """Chunkea texto en oraciones con anchors"""
        chunks = []

        # Dividir en oraciones
        oraciones = re.split(r"[.!?]+", texto)
        oraciones = [o.strip() for o in oraciones if o.strip()]

        # Crear chunks de 2-3 oraciones
        chunk_size = 3
        for i in range(0, len(oraciones), chunk_size):
            chunk_oraciones = oraciones[i : i + chunk_size]
            chunk_texto = ". ".join(chunk_oraciones) + "."

            # Generar anchors √∫nicos
            anchors = []
            for j, oracion in enumerate(chunk_oraciones):
                anchor = f"{prefijo}_oracion_{i+j}_{hashlib.md5(oracion.encode()).hexdigest()[:8]}"
                anchors.append(anchor)

            # Extraer entidades clave (simplificado)
            entidades = self._extraer_entidades_clave(chunk_texto)

            chunk = ChunkConAnchors(
                texto=chunk_texto,
                inicio_char=0,  # Simplificado
                fin_char=len(chunk_texto),
                seccion=seccion,
                parrafo=i // chunk_size,
                oraciones=chunk_oraciones,
                anchors=anchors,
                entidades_clave=entidades,
                relevancia_clinica=0.8,  # Valor por defecto
            )

            chunks.append(chunk)

        return chunks

    def _extraer_entidades_clave(self, texto: str) -> List[str]:
        """Extrae entidades clave del texto"""
        # Implementaci√≥n simplificada
        entidades_clave = [
            "dolor",
            "ejercicio",
            "tratamiento",
            "terapia",
            "rehabilitaci√≥n",
            "rodilla",
            "articulaci√≥n",
            "fisioterapia",
            "mejora",
            "efectividad",
        ]

        encontradas = []
        texto_lower = texto.lower()
        for entidad in entidades_clave:
            if entidad in texto_lower:
                encontradas.append(entidad)

        return encontradas

    def _simular_texto_completo(self, resultado: ResultadoBusqueda) -> str:
        """Simula texto completo del art√≠culo"""
        return f"""
{resultado.abstract}

Methods: This study employed a randomized controlled design with 100 participants.

Results: Significant improvements were observed in pain reduction (p<0.001) and functional outcomes.

Discussion: The findings support the effectiveness of the intervention for managing symptoms.

Conclusion: This treatment approach shows promising results for clinical practice.
"""


class LLMSummarizer:
    """LLM Summarizer "con evidencia requerida" """

    def __init__(self):
        self.prompt_template = """
Sistema (oculto al usuario)

Eres un asistente cl√≠nico que genera respuestas basadas exclusivamente en evidencia encontrada en bases biom√©dicas.
Objetivo: producir un informe breve, claro y coherente para profesionales de la salud, en espa√±ol, con el siguiente orden fijo:

Introducci√≥n (2‚Äì4 frases), 2) Evaluaci√≥n/Examen (pruebas, escalas), 3) Diagn√≥stico (diferencial, criterios, im√°genes), 4) Tratamiento/Terapia (conservador y/o quir√∫rgico; dosis, frecuencia, progresiones), 5) Cierre/S√≠ntesis (take-home), 6) Referencias (formato APA 7).

Reglas de citaci√≥n:
- Inserta marcadores [n] en el texto en cada afirmaci√≥n que requiera respaldo (m√°x. 1‚Äì2 por frase).
- En "Referencias" lista solo las obras citadas con coincidencia 1:1 respecto a los marcadores.
- Formato APA 7 corto (Autor, A√±o. T√≠tulo. Revista; volumen(n¬∫):p√°ginas. DOI/URL).

Evidencia: usa solo los √≠tems suministrados por el m√≥dulo de b√∫squeda (con t√≠tulo, autores, a√±o, DOI/URL). No inventes ni extrapoles m√°s all√° de lo que dicen los estudios.

Estilo: frases concisas, p√°rrafos de 3‚Äì5 l√≠neas, voz activa, sin jerga innecesaria.

Seguridad: si la evidencia es limitada o conflictiva, decl√°ralo y sugiere decisiones compartidas.
Si faltan datos cr√≠ticos para una recomendaci√≥n (p. ej., dosis), ind√≠calo como "no concluyente [n]".
Si no hay evidencia suficiente, entregar "Hallazgos insuficientes para conclusiones", m√°s una lista de vac√≠os.

Longitud: 250‚Äì600 palabras (seg√∫n complejidad).
No uses bullets en Referencias; usa lista numerada.

EVIDENCIA DISPONIBLE:
{chunks_texto}

Salida estrictamente en el siguiente esquema Markdown:

## Introducci√≥n
{{contexto breve con 2‚Äì4 frases y 1‚Äì2 citas [n]}}

## Evaluaci√≥n / Examen
{{signos, pruebas cl√≠nicas, escalas, umbrales, cu√°ndo pedir im√°genes; incluir sensibilidad/especificidad si est√°n reportadas [n]}}

## Diagn√≥stico
{{criterios, diagn√≥stico diferencial, algoritmos, cu√°ndo derivar; l√≠mites de evidencia [n]}}

## Tratamiento / Terapia
{{opciones conservadoras y/o quir√∫rgicas; par√°metros: tipo, dosis, frecuencia, duraci√≥n; progresiones; efectos adversos; calidad de evidencia [n]}}

## Cierre
{{s√≠ntesis pr√°ctica en 3‚Äì5 puntos o 4‚Äì6 l√≠neas [n]}}

## Referencias
1. {{APA de la cita [1]}}
2. {{APA de la cita [2]}}
...
"""

    def resumir_con_evidencia(
        self, chunks: List[ChunkConAnchors], consulta: str
    ) -> ResumenConEvidencia:
        """Genera resumen con evidencia requerida"""
        logger.info(f"üß† Generando resumen con evidencia de {len(chunks)} chunks")

        # Preparar chunks para el LLM
        chunks_texto = self._preparar_chunks_para_llm(chunks)

        # Generar prompt
        prompt = self.prompt_template.format(chunks_texto=chunks_texto)

        # Llamar al LLM (simulado)
        respuesta_llm = self._llm_summarize(prompt)

        # Procesar respuesta
        resumen_procesado = self._procesar_respuesta_llm(respuesta_llm, chunks)

        logger.info(f"‚úÖ Resumen con evidencia generado")
        return resumen_procesado

    def _preparar_chunks_para_llm(self, chunks: List[ChunkConAnchors]) -> str:
        """Prepara chunks para el LLM"""
        chunks_texto = []
        for i, chunk in enumerate(chunks):
            chunks_texto.append(
                f"""
CHUNK {i+1} [ID: {chunk.anchors[0]}]:
{chunk.texto}
"""
            )
        return "\n".join(chunks_texto)

    def _llm_summarize(self, prompt: str) -> str:
        """Llama al LLM real para resumir la evidencia cient√≠fica"""
        try:
            # Importar OpenAI para llamar al LLM real
            from openai import OpenAI
            import os

            # Configurar cliente OpenAI
            api_key = (
                os.getenv("OPENROUTER_API_KEY")
                or "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"
            )
            client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

            # Llamar al LLM real
            completion = client.chat.completions.create(
                model="deepseek/deepseek-r1:free",
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un asistente m√©dico especializado en an√°lisis de evidencia cient√≠fica. Tu objetivo es proporcionar an√°lisis claros, estructurados y cl√≠nicamente relevantes basados en la evidencia disponible. Usa lenguaje profesional pero accesible, enf√≥cate en hallazgos aplicables y mant√©n un formato organizado.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,  # Baja temperatura para respuestas m√°s consistentes
                max_tokens=1000,
            )

            # Extraer respuesta del LLM
            respuesta_llm = completion.choices[0].message.content.strip()
            logger.info(f"‚úÖ LLM real llamado exitosamente")

            return respuesta_llm

        except Exception as e:
            logger.error(f"‚ùå Error llamando al LLM real: {e}")
            logger.warning("‚ö†Ô∏è Usando respuesta simulada como fallback")

            # Respuesta simulada como fallback
            return """
El ejercicio f√≠sico reduce significativamente el dolor de rodilla [CHUNK1].

La fisioterapia mejora la funci√≥n articular [CHUNK2].

La rehabilitaci√≥n supervisada es m√°s efectiva que el ejercicio no supervisado [CHUNK3].

NO CONCLUSIVO: No hay evidencia suficiente sobre la duraci√≥n √≥ptima del tratamiento.
"""

    def _procesar_respuesta_llm(
        self, respuesta: str, chunks: List[ChunkConAnchors]
    ) -> ResumenConEvidencia:
        """Procesa la respuesta del LLM con formato estructurado"""
        # Verificar si la respuesta tiene formato estructurado
        if "## Introducci√≥n" in respuesta or "## Evaluaci√≥n" in respuesta:
            return self._procesar_respuesta_estructurada(respuesta, chunks)
        else:
            return self._procesar_respuesta_simple(respuesta, chunks)

    def _procesar_respuesta_estructurada(
        self, respuesta: str, chunks: List[ChunkConAnchors]
    ) -> ResumenConEvidencia:
        """Procesa respuesta con formato estructurado (nuevo formato)"""
        oraciones_con_evidencia = []
        oraciones_sin_evidencia = []
        claims_no_concluyentes = []

        # Extraer marcadores de citas [n] del texto
        import re

        citas_encontradas = re.findall(r"\[(\d+)\]", respuesta)
        citas_unicas = list(set(citas_encontradas))

        # Contar oraciones con evidencia
        oraciones_con_citas = len(re.findall(r"\[(\d+)\]", respuesta))

        # Procesar cada secci√≥n
        secciones = respuesta.split("##")

        for seccion in secciones:
            if not seccion.strip():
                continue

            # Contar marcadores de citas en esta secci√≥n
            citas_seccion = re.findall(r"\[(\d+)\]", seccion)
            if citas_seccion:
                oraciones_con_evidencia.append(
                    {
                        "oracion": seccion.strip(),
                        "citas": citas_seccion,
                        "confianza": 0.9,
                    }
                )

        return ResumenConEvidencia(
            resumen=respuesta,
            oraciones_con_evidencia=oraciones_con_evidencia,
            oraciones_sin_evidencia=oraciones_sin_evidencia,
            claims_no_concluyentes=claims_no_concluyentes,
            confianza_global=0.85,
        )

    def _procesar_respuesta_simple(
        self, respuesta: str, chunks: List[ChunkConAnchors]
    ) -> ResumenConEvidencia:
        """Procesa respuesta simple (formato anterior)"""
        oraciones = respuesta.strip().split("\n")

        oraciones_con_evidencia = []
        oraciones_sin_evidencia = []
        claims_no_concluyentes = []

        for oracion in oraciones:
            if not oracion.strip():
                continue

            if "NO CONCLUSIVO" in oracion:
                claims_no_concluyentes.append(oracion)
            elif "[" in oracion and "]" in oracion:
                # Extraer citas
                citas = re.findall(r"\[(.*?)\]", oracion)
                oracion_limpia = re.sub(r"\[.*?\]", "", oracion).strip()

                oraciones_con_evidencia.append(
                    {"oracion": oracion_limpia, "citas": citas, "confianza": 0.9}
                )
            else:
                oraciones_sin_evidencia.append(oracion)

        return ResumenConEvidencia(
            resumen=respuesta,
            oraciones_con_evidencia=oraciones_con_evidencia,
            oraciones_sin_evidencia=oraciones_sin_evidencia,
            claims_no_concluyentes=claims_no_concluyentes,
            confianza_global=0.8,
        )


class VerificadorFactual:
    """Verificaci√≥n factual mejorada con RapidFuzz"""

    def __init__(self):
        self.umbral_similitud = 0.7
        self.umbral_entidades = 0.5
        # Importar el asignador mejorado de citas
        try:
            from citation_assigner_enhanced import citation_assigner_enhanced

            self.citation_assigner = citation_assigner_enhanced
            logger.info("‚úÖ VerificadorFactual mejorado con RapidFuzz")
        except ImportError:
            logger.warning("‚ö†Ô∏è RapidFuzz no disponible, usando verificaci√≥n b√°sica")
            self.citation_assigner = None

    def verificar_factual(
        self, resumen: ResumenConEvidencia, chunks: List[ChunkConAnchors]
    ) -> List[MapeoOracionCita]:
        """Verifica factualidad del resumen usando RapidFuzz si est√° disponible"""
        logger.info(
            f"üîç Verificaci√≥n factual de {len(resumen.oraciones_con_evidencia)} oraciones"
        )

        if self.citation_assigner:
            return self._verificar_con_rapidfuzz(resumen, chunks)
        else:
            return self._verificar_basico(resumen, chunks)

    def _verificar_con_rapidfuzz(
        self, resumen: ResumenConEvidencia, chunks: List[ChunkConAnchors]
    ) -> List[MapeoOracionCita]:
        """Verificaci√≥n usando RapidFuzz para mayor precisi√≥n"""
        from citation_assigner_enhanced import (
            ChunkMetadata,
            attach_citations_to_sentences_enhanced,
        )

        # Convertir chunks a formato compatible
        chunks_metadata = []
        for chunk in chunks:
            chunk_meta = ChunkMetadata(
                text=chunk.texto,
                source=(
                    chunk.anchors[0]
                    if chunk.anchors
                    else f"chunk_{len(chunks_metadata)}"
                ),
                span=(chunk.inicio_char, chunk.fin_char),
                meta={
                    "seccion": chunk.seccion,
                    "parrafo": chunk.parrafo,
                    "relevancia_clinica": chunk.relevancia_clinica,
                },
                apa_citation=f"CHUNK_{len(chunks_metadata)+1}",
                entidades_clave=chunk.entidades_clave,
            )
            chunks_metadata.append(chunk_meta)

        # Extraer oraciones del resumen
        oraciones = []
        for oracion_data in resumen.oraciones_con_evidencia:
            oraciones.append(oracion_data["oracion"])

        # Usar asignador mejorado
        chunks_dict = []
        for chunk_meta in chunks_metadata:
            chunks_dict.append(
                {
                    "text": chunk_meta.text,
                    "source": chunk_meta.source,
                    "span": chunk_meta.span,
                    "meta": chunk_meta.meta,
                    "relevancia_score": chunk_meta.relevancia_score,
                    "entidades_clave": chunk_meta.entidades_clave,
                }
            )

        # Asignar citas usando RapidFuzz
        resultados = attach_citations_to_sentences_enhanced(
            oraciones, chunks_dict, sim_threshold=0.65
        )

        # Convertir a MapeoOracionCita
        mapeos = []
        for i, resultado in enumerate(resultados):
            oracion = resultado["sentence"]
            mapeo = MapeoOracionCita(
                oracion_id=hashlib.md5(oracion.encode()).hexdigest()[:8],
                oracion_texto=oracion,
                citas=resultado["citations"],
                chunks_soporte=resultado["chunks_soporte"],
                confianza=resultado["confianza"],
                timestamp=datetime.now(),
            )
            mapeos.append(mapeo)

        logger.info(f"‚úÖ Verificaci√≥n factual con RapidFuzz completada")
        return mapeos

    def _verificar_basico(
        self, resumen: ResumenConEvidencia, chunks: List[ChunkConAnchors]
    ) -> List[MapeoOracionCita]:
        """Verificaci√≥n b√°sica sin RapidFuzz"""
        mapeos = []

        for oracion_data in resumen.oraciones_con_evidencia:
            oracion = oracion_data["oracion"]
            citas = oracion_data["citas"]

            # Verificar cada cita
            chunks_soporte = []
            confianza_total = 0.0

            for cita in citas:
                chunk_soporte = self._encontrar_chunk_soporte(cita, chunks)
                if chunk_soporte:
                    chunks_soporte.append(chunk_soporte.anchors[0])
                    confianza_total += self._calcular_confianza_oracion(
                        oracion, chunk_soporte
                    )

            # Calcular confianza promedio
            confianza_promedio = (
                confianza_total / len(chunks_soporte) if chunks_soporte else 0.0
            )

            # Crear mapeo
            mapeo = MapeoOracionCita(
                oracion_id=hashlib.md5(oracion.encode()).hexdigest()[:8],
                oracion_texto=oracion,
                citas=citas,
                chunks_soporte=chunks_soporte,
                confianza=confianza_promedio,
                timestamp=datetime.now(),
            )

            mapeos.append(mapeo)

        logger.info(f"‚úÖ Verificaci√≥n factual b√°sica completada")
        return mapeos

    def _encontrar_chunk_soporte(
        self, cita: str, chunks: List[ChunkConAnchors]
    ) -> Optional[ChunkConAnchors]:
        """Encuentra chunk que soporta una cita"""
        for chunk in chunks:
            if cita in chunk.anchors[0]:
                return chunk
        return None

    def _calcular_confianza_oracion(
        self, oracion: str, chunk: ChunkConAnchors
    ) -> float:
        """Calcula confianza de una oraci√≥n contra un chunk"""
        # Similitud de texto
        similitud_texto = self._calcular_similitud_texto(oracion, chunk.texto)

        # Similitud de entidades
        similitud_entidades = self._calcular_similitud_entidades(
            self._extraer_entidades(oracion), chunk.entidades_clave
        )

        # Confianza combinada
        confianza = (similitud_texto + similitud_entidades) / 2
        return min(1.0, max(0.0, confianza))

    def _calcular_similitud_texto(self, texto1: str, texto2: str) -> float:
        """Calcula similitud de texto"""
        palabras1 = set(texto1.lower().split())
        palabras2 = set(texto2.lower().split())

        if not palabras1 or not palabras2:
            return 0.0

        intersection = palabras1 & palabras2
        union = palabras1 | palabras2

        return len(intersection) / len(union)

    def _calcular_similitud_entidades(
        self, entidades1: List[str], entidades2: List[str]
    ) -> float:
        """Calcula similitud de entidades"""
        if not entidades1 or not entidades2:
            return 0.0

        intersection = set(entidades1) & set(entidades2)
        union = set(entidades1) | set(entidades2)

        return len(intersection) / len(union)

    def _extraer_entidades(self, texto: str) -> List[str]:
        """Extrae entidades del texto"""
        # Implementaci√≥n simplificada
        entidades_clave = [
            "dolor",
            "ejercicio",
            "tratamiento",
            "terapia",
            "rehabilitaci√≥n",
            "rodilla",
            "articulaci√≥n",
            "fisioterapia",
            "mejora",
            "efectividad",
        ]

        encontradas = []
        texto_lower = texto.lower()
        for entidad in entidades_clave:
            if entidad in texto_lower:
                encontradas.append(entidad)

        return encontradas


class FormateadorAPAFinal:
    """APA + Render final"""

    def __init__(self):
        self.formateador = None  # Se inicializar√° con el formateador APA existente

    def formatear_final(
        self, mapeos: List[MapeoOracionCita], resultados: List[ResultadoBusqueda]
    ) -> str:
        """Formatea resultado final con citas APA"""
        logger.info(f"üìö Formateando resultado final con {len(mapeos)} mapeos")

        # Crear diccionario de resultados por DOI
        resultados_dict = {r.doi: r for r in resultados}

        # Formatear cada oraci√≥n con citas APA
        oraciones_formateadas = []

        for mapeo in mapeos:
            citas_apa = []
            for chunk_id in mapeo.chunks_soporte:
                # Encontrar resultado correspondiente
                for resultado in resultados:
                    if resultado.doi in chunk_id:
                        cita_apa = self._formatear_cita_apa(resultado)
                        citas_apa.append(cita_apa)
                        break

            if citas_apa:
                oracion_con_citas = f"{mapeo.oracion_texto} ({', '.join(citas_apa)})"
            else:
                oracion_con_citas = f"{mapeo.oracion_texto} [sin cita]"

            oraciones_formateadas.append(oracion_con_citas)

        # Crear resultado final
        resultado_final = "\n\n".join(oraciones_formateadas)

        logger.info(f"‚úÖ Resultado final formateado")
        return resultado_final

    def _formatear_cita_apa(self, resultado: ResultadoBusqueda) -> str:
        """Formatea cita APA para un resultado"""
        # Formato simplificado APA
        if len(resultado.autores) == 1:
            autores = resultado.autores[0]
        elif len(resultado.autores) <= 3:
            autores = " & ".join(resultado.autores)
        else:
            autores = ", ".join(resultado.autores[:2]) + " et al."

        return f"{autores} ({resultado.a√±o})"


class UnifiedOrchestrationSystem:
    """Sistema de Orquestaci√≥n RAG Cl√≠nico Completo"""

    def __init__(self):
        logger.info("üéØ Inicializando Sistema de Orquestaci√≥n RAG Cl√≠nico")

        # Inicializar componentes
        self.generador_terminos = GeneradorTerminosPICO()
        self.recuperador_dual = RecuperadorDual()
        self.filtrador = FiltradorEstudios()
        self.reranker = ReRankerClinico()
        self.chunker = ChunkerConAnchors()
        self.summarizer = LLMSummarizer()
        self.verificador = VerificadorFactual()
        self.formateador = FormateadorAPAFinal()

        logger.info("‚úÖ Sistema de Orquestaci√≥n RAG Cl√≠nico inicializado")

    def ejecutar_pipeline_completo(
        self, consulta: str, analisis_nlp: Dict[str, Any]
    ) -> ResultadoOrquestacion:
        """Ejecuta el pipeline completo de orquestaci√≥n"""
        start_time = time.time()

        logger.info(f"üéØ Ejecutando pipeline completo para: {consulta[:50]}...")

        try:
            # INTEGRACI√ìN MeSH: Normalizar consulta y generar t√©rminos mejorados
            mesh_descriptor = mesh_integration.normalize_medical_term(consulta)

            if mesh_descriptor:
                logger.info(
                    f"‚úÖ T√©rmino normalizado MeSH: '{consulta}' ‚Üí '{mesh_descriptor.label}'"
                )

                # Generar t√©rminos de b√∫squeda mejorados con MeSH
                enhanced_terms = mesh_integration.get_enhanced_search_terms(consulta)

                # Obtener contexto cl√≠nico
                clinical_context = mesh_integration.get_clinical_context(
                    mesh_descriptor
                )
                logger.info(
                    f"üè• Contexto cl√≠nico: {clinical_context['specialty']} - {clinical_context['category']}"
                )

                # Agregar t√©rminos MeSH al an√°lisis NLP
                analisis_nlp["mesh_terms"] = enhanced_terms
                analisis_nlp["mesh_descriptor"] = mesh_descriptor.label
                analisis_nlp["clinical_context"] = clinical_context
            else:
                logger.warning(f"‚ö†Ô∏è No se pudo normalizar con MeSH: {consulta}")

            # Paso 1: Generar t√©rminos PICO mejorados con MeSH
            terminos = self.generador_terminos.generar_terminos(consulta, analisis_nlp)
            logger.info(f"üìù {len(terminos)} t√©rminos generados (incluyendo MeSH)")

            # Paso 2: Recuperaci√≥n dual (BM25 + Embeddings)
            resultados_recuperados = self.recuperador_dual.recuperar_dual(terminos)
            logger.info(f"üîç {len(resultados_recuperados)} resultados recuperados")

            # Paso 3: Filtrado por dise√±o de estudio + a√±o + peer-review
            resultados_filtrados = self.filtrador.filtrar_resultados(
                resultados_recuperados
            )
            logger.info(
                f"üîç {len(resultados_filtrados)} resultados despu√©s del filtrado"
            )

            # Paso 4: Re-ranking cl√≠nico
            resultados_reranked = self.reranker.rerank_clinico(
                resultados_filtrados, consulta
            )
            logger.info(f"üîÑ Re-ranking cl√≠nico completado")

            # Paso 5: Chunking con anchors
            chunks = self.chunker.chunkear_con_anchors(resultados_reranked)
            logger.info(f"üìÑ {len(chunks)} chunks creados con anchors")

            # Paso 6: LLM Summarizer con evidencia requerida
            resumen = self.summarizer.resumir_con_evidencia(chunks, consulta)
            logger.info(f"üß† Resumen con evidencia generado")

            # Paso 7: Verificaci√≥n factual
            mapeos = self.verificador.verificar_factual(resumen, chunks)
            logger.info(f"üîç Verificaci√≥n factual completada")

            # Paso 8: Formateo APA final
            resultado_final = self.formateador.formatear_final(
                mapeos, resultados_reranked
            )
            logger.info(f"üìö Formateo APA final completado")

            # INTEGRACI√ìN MedlinePlus: Obtener educaci√≥n del paciente
            patient_education = {}
            education_available = False

            if mesh_descriptor and clinical_context:
                try:
                    patient_education = self._get_patient_education(
                        consulta, clinical_context
                    )
                    education_available = patient_education.get("show_panel", False)

                    # Agregar educaci√≥n del paciente al resumen
                    resumen.patient_education = patient_education
                    resumen.education_available = education_available
                    resumen.education_summary = patient_education.get("content", "")

                    logger.info(
                        f"üìö Educaci√≥n del paciente agregada: {patient_education.get('title', 'N/A')}"
                    )
                except Exception as e:
                    logger.error(f"‚ùå Error obteniendo educaci√≥n del paciente: {e}")

            # Calcular tiempo total
            tiempo_total = time.time() - start_time

            # Crear estad√≠sticas
            estadisticas = {
                "terminos_generados": len(terminos),
                "resultados_recuperados": len(resultados_recuperados),
                "resultados_filtrados": len(resultados_filtrados),
                "chunks_creados": len(chunks),
                "oraciones_con_evidencia": len(resumen.oraciones_con_evidencia),
                "oraciones_sin_evidencia": len(resumen.oraciones_sin_evidencia),
                "claims_no_concluyentes": len(resumen.claims_no_concluyentes),
                "mapeos_verificados": len(mapeos),
            }

            # Crear resultado final
            resultado = ResultadoOrquestacion(
                consulta_original=consulta,
                terminos_busqueda=terminos,
                resultados_recuperados=resultados_reranked,
                chunks_procesados=chunks,
                resumen_final=resumen,
                mapeo_oracion_cita=mapeos,
                tiempo_total=tiempo_total,
                estadisticas=estadisticas,
            )

            logger.info(f"‚úÖ Pipeline completo ejecutado en {tiempo_total:.2f}s")
            return resultado

        except Exception as e:
            logger.error(f"‚ùå Error en pipeline: {e}")
            # Retornar resultado de error
            return self._resultado_error(consulta, str(e))

    def _resultado_error(self, consulta: str, error: str) -> ResultadoOrquestacion:
        """Genera resultado de error"""
        return ResultadoOrquestacion(
            consulta_original=consulta,
            terminos_busqueda=[],
            resultados_recuperados=[],
            chunks_procesados=[],
            resumen_final=ResumenConEvidencia(
                resumen="Error en el procesamiento del pipeline.",
                oraciones_con_evidencia=[],
                oraciones_sin_evidencia=[],
                claims_no_concluyentes=[f"Error t√©cnico: {error}"],
                confianza_global=0.0,
            ),
            mapeo_oracion_cita=[],
            tiempo_total=0.0,
            estadisticas={"error": error},
        )

    def _get_patient_education(
        self, query: str, clinical_context: Dict[str, str]
    ) -> Dict[str, str]:
        """
        Obtiene informaci√≥n educativa para el paciente usando MedlinePlus

        Args:
            query: Consulta original del usuario
            clinical_context: Contexto cl√≠nico determinado por MeSH

        Returns:
            Dict con informaci√≥n educativa formateada
        """
        try:
            # Determinar tipo de c√≥digo basado en contexto
            specialty = clinical_context.get("specialty", "General")

            # Mapeo de especialidades a tipos de c√≥digos m√°s probables
            code_type_mapping = {
                "Musculoskeletal": "diagnosis",  # ICD-10 para lesiones
                "Therapeutics": "medication",  # RxCUI para medicamentos
                "Cardiology": "diagnosis",  # ICD-10 para condiciones card√≠acas
                "Neurology": "diagnosis",  # ICD-10 para condiciones neurol√≥gicas
                "Respiratory": "diagnosis",  # ICD-10 para condiciones respiratorias
                "Oncology": "diagnosis",  # ICD-10 para c√°ncer
                "General": "diagnosis",  # Por defecto
            }

            code_type = code_type_mapping.get(specialty, "diagnosis")

            # Por ahora, retornamos informaci√≥n educativa gen√©rica
            # En una implementaci√≥n completa, se extraer√≠an c√≥digos espec√≠ficos
            education_info = {
                "title": f"üìö Informaci√≥n sobre {query}",
                "content": f"Obt√©n informaci√≥n educativa oficial sobre {query} en MedlinePlus.gov",
                "url": f"https://medlineplus.gov/spanish/search.html?query={quote(query)}",
                "show_panel": True,
                "source": "MedlinePlus.gov",
                "language": "es",
                "code_type": code_type,
                "specialty": specialty,
            }

            logger.info(f"‚úÖ Informaci√≥n educativa preparada para: {query}")
            return education_info

        except Exception as e:
            logger.error(f"‚ùå Error obteniendo educaci√≥n del paciente: {e}")
            return {
                "title": "Informaci√≥n educativa",
                "content": "Informaci√≥n educativa disponible en MedlinePlus.gov",
                "url": "https://medlineplus.gov/spanish/",
                "show_panel": False,
                "source": "MedlinePlus.gov",
                "language": "es",
            }


# Instancia global del sistema de orquestaci√≥n
unified_orchestration = UnifiedOrchestrationSystem()


def test_orchestration_system():
    """Funci√≥n de prueba para el sistema de orquestaci√≥n"""
    print("üéØ Probando Sistema de Orquestaci√≥n RAG Cl√≠nico")
    print("=" * 60)

    # An√°lisis NLP de prueba
    analisis_nlp_prueba = {
        "sintomas": ["dolor de rodilla", "rigidez articular"],
        "organos": ["rodilla", "articulaci√≥n"],
        "medicamentos": ["paracetamol", "ibuprofeno"],
        "pico_terms": {
            "P": ["pacientes con osteoartritis"],
            "I": ["ejercicio f√≠sico", "fisioterapia"],
            "C": ["tratamiento est√°ndar"],
            "O": ["reducci√≥n del dolor", "mejora funcional"],
        },
    }

    # Casos de prueba
    casos_prueba = [
        "¬øQu√© tratamientos son efectivos para el dolor de rodilla?",
        "¬øCu√°l es la evidencia sobre fisioterapia para osteoartritis?",
        "¬øQu√© ejercicios recomiendan para rehabilitaci√≥n de rodilla?",
    ]

    for i, caso in enumerate(casos_prueba, 1):
        print(f"\nüîç Caso {i}: {caso}")

        start_time = time.time()
        resultado = unified_orchestration.ejecutar_pipeline_completo(
            caso, analisis_nlp_prueba
        )
        tiempo = time.time() - start_time

        print(f"   ‚úÖ Tiempo: {tiempo:.2f}s")
        print(f"   üìù T√©rminos: {resultado.estadisticas['terminos_generados']}")
        print(f"   üîç Recuperados: {resultado.estadisticas['resultados_recuperados']}")
        print(f"   üîç Filtrados: {resultado.estadisticas['resultados_filtrados']}")
        print(f"   üìÑ Chunks: {resultado.estadisticas['chunks_creados']}")
        print(
            f"   üìù Con evidencia: {resultado.estadisticas['oraciones_con_evidencia']}"
        )
        print(
            f"   ‚ö†Ô∏è Sin evidencia: {resultado.estadisticas['oraciones_sin_evidencia']}"
        )
        print(
            f"   ‚ùì No concluyentes: {resultado.estadisticas['claims_no_concluyentes']}"
        )
        print(f"   üîç Mapeos: {resultado.estadisticas['mapeos_verificados']}")

        # Mostrar resumen
        if resultado.resumen_final.resumen:
            print(f"   üìã Resumen: {resultado.resumen_final.resumen[:100]}...")

    print("\n‚úÖ Pruebas del sistema de orquestaci√≥n completadas!")


if __name__ == "__main__":
    test_orchestration_system()
